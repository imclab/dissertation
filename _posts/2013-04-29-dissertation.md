## Abstract

This dissertation will overview the emergent trends in evolutional trends of HCI and its focus on embodiment and human-centred

This dissertation will review Mark Weiser’s vision of ubiquitous computing and the 

It will also look at the phenomenological underpinning of ubiquitous computing, focussing on Paul Dourish’s comprehensive study of the philosophies of Husserl and Heidegger

Moving onto tangible computing.

Insight into affordances from Gibson, Norman and Gaver.

A look into aesthetics and emotional design, its impact on usability and the invisibility of computing.

Ambience as a response to lots of tech.

This dissertation concerns itself with the relationship between humans and computers. It grounds itself in Mark Weiser’s prescient vision of the third great paradigm of computing, ubiquitous computing. Identifying his notions of embodied virtuality and calm computing as avenues through which we can explore the fields of tangible computing and ambient media.

It gives an overview of the underlying phenomenological foundations of ubiquitous computing, contrasted with virtual reality and the model of cartesian dualism, according to Paul Dourish and with reference to the philosophy of Heidegger and Husserl.

It pays attention to the field of tangible computing and how it capitalises on users’ inherent familiarity with everyday world to …



**Keywords:** Ubiquitous Computing, Physical Computing, Tangible Computing, Pervasive Computing, Internet of Things, Embodied Interaction, Post-WIMP, Tangible Interfaces, Reality-Based Interfaces, Human Computer Interaction, Ecological Psychology, Affordances, Product Design, Interaction Design, Emotional Design, User-Centred Design.

## Introduction

The artefacts of Today’s modern computing technology are almost unrecognisable as descendants of their primitive predecessors. The computer entered the commercial market as a static behemoth that resided almost exclusively in the cupboards, back rooms and basements of corporate and governmental offices. It had no single operator; its time and resources were shared between multiple users. This was the era of the mainframe computer.

The first major paradigm shift occurred in the 1980’s, as the mainframe escaped its dimly-lit confines and fixed itself firmly and securely to the desktops of individual employees and hobbyists. The computer-to-human relationship was a one-to-one affair, and so began the age of the personal computer. As the personal computer rose to prominence as its numbers and use grew, it did so surrounded by somewhat of an ‘arcane aura’ (Weiser, Page 94, The Computer for the 21st Century). It spoke a different language, indecipherable to everyday folk. It operated outside of the confines of everyday life, accessible only whilst seated before it at a desk. Its form and the mode by which we interacted with it were changing very little. It was yet to undergo anything akin to a metamorphosis; still a far cry from the techno-utopian futures that had been promised by science fiction. In an ‘age of beige boxes’ (Dourish, Page 27, Where the Action Is), something more than a newly designed cuboid was necessary to change the nature of computing as we knew it. Something had to happen at a fundamental level, a re-imagining of our future and the role that computers played in it.

Mark Weiser witnessed the rise of the personal computer whilst head of the Computer Science Lab (CSL) at Xerox’s Palo Alto Research Centre (PARC) in California. The interdisciplinarity of PARC exposed Weiser to the ideas, thoughts and insights of sociologists, psychologists, and anthropologists, which ultimately inspired him and his colleagues ‘to take a radical look at what computing and networking ought to be like’ (Weiser, Ubiquitous Computing #1). Weiser envisioned a type of computing that was ubiquitous. It was the inverse of its mainframe predecessor; providing each user with many devices, in the tens if not hundreds. Ubiquitous computing (ubicomp) would see computers present at each and every level of our day-to-day lives, ‘imbedded in walls, chairs, clothing, light switches, cars - in everything’ (Weiser and Brown, Page 4, The Coming Age of Calm Technology). Ubicomp is defined not just by the abundance of computers, but also by their persistent and total connectedness, and the underlying infrastructures that facilitate such a thing.

PARC stayed true to its philosophy of “Build what you use, and use what you build” (Want, Page 6, An Introduction to Ubiquitous Computing [Ubiquitous Computing Fundamentals]) and, under the guidance of Weiser, embarked on a project to realise ubicomp. Given the high cost and limited capabilities of existing technologies, it was — slightly ironically — ubiquitousness on a small-scale. However, it provided the CSL team with the necessary environment in which to explore the requirements, effects, and emergent traits of ubicomp.

Weiser’s vision and the work being undertaken at PARC was not going unnoticed in the wider world. Throughout the 90s ubicomp influenced a number of projects that explored the possibilities of this kind of computing. Projects that took place in both corporate and academic research labs, run by the likes of IBM and Hewlett Packard, MIT and Georgia Tech. With each new project came a new term that more succinctly conveyed the nature of its unique brand of ubiquitous computing, whether for marketing reasons or otherwise. Such terms include pervasive, tangible, and physical, some of which I will return to in the coming chapters.

The fundamental characteristics of ubiquitous computing that Weiser himself — explicitly and implicitly — outlined in ‘The Computer for the 21st Century’ and publishings thereafter will form the basis of this dissertation. Characteristics which addressed aspects of the current paradigm of personal computing and set the precedent for technologies that would more appropriately fit themselves to the real-world and capitalise on our familiarity with it. The refinement of these characteristics in the new fields that emerged in the wake of ubicomp will build on this base, conducted through the exploration and analysis of the archetypal projects from each area.

A most critical aspect of Weiser’s vision for a ubiquitous computing, one which can clearly be seen in the projects that it has both influenced and given rise to, is the concept of embodiment. It’s first mentioned in the context of ‘embodied virtuality’ (Weiser, Page 98, The Computer for the 21st Century) as the notion of ‘drawing computers from their electronic shells. The “virtuality” of computer-readable data -- all the different ways in which it can be altered, processed and analyzed -- is brought into the physical world’ (Weiser, Page 98, The Computer for the 21st Century). It’s the philosophical, psychological, and sociological underpinning of the ubiquitous computing paradigm, and will be the topic of the first chapter of this dissertation. It will call upon the work of Paul Dourish regarding embodied interaction. Focussing on his analysis of the phenomenological traditions founded by Edmund Husserl and further developed by Martin Heidegger.

The thought of computational devices being inherently ‘calm’ is perhaps at odds with the situation we find ourselves in Today — surrounded by a plethora of gizmos and gadgets, each vying for our attention with its incessant bleeping, chirping, and rumbling. Weiser and Brown (1996, Page 7) warned that ‘if computers are everywhere they better stay out of the way’ (Weiser and Brown, Page 7, The Coming Age of Calm Technology). Efforts to make computing more ambient and natural will be the focus of my second chapter.

In the 1990s, in an effort to join the worlds of atoms and bits, the MIT Tangible Media group developed a number of projects under the umbrella of tangible computing. 

In the final chapter, I will review the current state and direction of ubiquitous computing, contextualising it within the larger technological landscape. Giving reference to the likes of Adam Greenfield and Bruce Sterling with the aim of identifying new characteristics that have emerged from its maturation in the last two decades.

## Embodiment

The notion of embodiment is the foundational underpinning of ubiquitous computing, it rudimentarily concerns itself with the fact that ‘humans are of and in the everyday world’ (Weiser, 1993, Some Computer Science Issues of Ubiquitous Computing). Dourish (2001) reviews the philosophy of embodiment in the context of tangible and social computing in his book ‘Where the Action Is’ and this publication will be the focus of this chapter.

Dourish (2001) reviewed the philosophical foundations and backgrounds of tangible and social computing, showing that both approaches were based around the same idea of embodied interaction.

> extend this introduction to include more relevant terms?

At around the same time that ubiquitous computing was finding its feet, ideas and technologies surrounding the starkly contrasted approach of virtual reality were also building up steam. Virtual reality proposes a model that seeks to inhabit the user in a computer-generated world. It detaches our consciousness from its fleshy confines and beams it into the fictional environment which it has created for us. A three-dimensional space designed to resemble the real world — often complete with naive physics, occlusion, and even proprioception — as to exploit our familiarity with the nature and structure of it. This use of the real world as a metaphor for interaction is distinctly different to using at as medium for interaction (Dourish, Page 101, Where the Action Is). Even in the most immersive virtual reality environments, ‘users are disconnected observers of a world they do not inhabit directly’ (Dourish, Page 102, Where the Action Is). Just as ‘…a disembodied brain could not experience the world in the same way we do’ (Dourish, Page 18, Where the Action Is), nor can our disconnected consciousness inhabit a virtual reality, ‘because our experience of the world is intimately tied to the ways in which we act in it’ (Dourish, Page 18, Where the Action Is).

> There is no homunculus sitting inside our heads, staring out at the world through our eyes, enacting some pan of action by manipulating our hands, and checking carefully to make sure that we don’t overshoot when reaching for the coffee cup. We inhabit our bodies and they in turn inhabit the world, with seamless connections back and forth’ (Dourish, Page 102, Where the Action Is).

Cartesian dualism, closely associated with the philosophy of René Descartes, separates the mind and body as two distinctly different entities — to ‘think’ and to ‘be’ are two disparate sets of phenomena (Dourish, Page 107, Where the Action Is). It’s clear that virtual reality adheres to this notion, but as we will now see, ubiquitous computing complies more with the phenomenological tradition that followed on from these ideas of duality.

Weiser (1991) alludes to the contrasting stance of ubiquitous computing with his use of the phrase ‘embodied virtuality’ (Weiser, Page 98, The Computer for the 21st Century). Rather than the user entering the computer’s domain, the computer is lured from its electronic shell into the real world — ‘The site of interaction is the world of the user, not that of the system. The world … may be imbued with computation, but the computer itself takes a back seat’ (Dourish, Page 38, Where the Action Is).

Phenomenology was founded by Edmund Husserl (1859-1938) as an exploration of human experience and perception (Dourish, Page 104, Where the Action Is). Husserl was attempting to address the abstract and idealised approach of scientists and mathematicians of the era. Such methodologies distanced themselves and their work from everyday practical concerns, and in doing so, the live experience of people acting in the world. Husserl ‘envisioned a science that was firmly grounded on the phenomena of experience, which in turn meant developing the philosophy of experience as a rigorous science’ (Dourish, Page 105, Where the Action Is).

Husserl proposed phenomenology as a method for examining the nature of intentionality; the way mental states could refer to elements of external reality. It aims to uncover the relationship between the objects of consciousness and our mental experiences of them — how ‘noema’ relate to ‘noesis’. Phenomenologists must not assume an objects existence based on its perception — for this is its objective, to understand how in perceiving something we assume its existence.

Husserl states that there is a parallelism between the objects of perception and the acts of perception. For example, when I see a rabbit, I have not only to recognise that what I’m seeing is a rabbit, but also that what I’m doing is seeing it (as opposed to imagining it or remembering it). Husserl saw that mental acts could become phenomena of experience as one referred and reflected on them (Dourish, Page 105, Where the Action Is). When an individual recognises that what they are seeing is a rabbit they move from the world of everyday affairs, beyond the sensory stimuli, and into the life-world. ‘The life-world [or lebenswelt] is the intersubjective, mundane world of background understandings and experiences of the world’ (Dourish, Pages 105-106, Where the Action Is).

Martin Heidegger (1889-1976) was a student of Husserl and used his work on phenomenology as a starting point as he too sought to uncover to intentionality of experience. Heidegger, however, saw his predecessor’s focus on mental phenomena occurring in isolation from the body as fundamentally flawed. He reversed Descartes’ dictum ‘cogito ergo sum’ to propose that ‘clearly one needed to be in order to think’ (Dourish, Page 107, Where the Action Is). To Heidegger, our being in the world and our experience of it shapes the way we understand it ‘because our understanding of the world is essentially an understanding of how we are in it’ (Dourish, Page 107, Where the Action Is). Descartes saw that the mind was the seat of reason and meaning — we observe the world and give it meaning by relating it to abstract understandings of (an idealised) reality. Heidegger situated the meaningfulness of everyday experience, not in the head, but in the world. ‘Heidegger asked, “How does the world reveal itself to us through our encounters with it?”’ (Dourish, Page 107, Where the Action Is).

‘Meaning inheres in the world as we find it’ (Dourish, Page 108, Where the Action Is) — the things we do, practically, and the ways in which we act and how this action is accommodated in the world is what makes the world meaningful to us. At the heart of this thinking is Heidegger’s concept of Dasein, the essence of being human and how ‘being’ is inseparable from the world in which it occurs (Dourish, Page 108, Where the Action Is). Dasein’s orientation toward the world is a fundamentally practical one, but action is not just carried out on the world, but also through it. Dasein’s use of tools and equipment, the distinction between the two, together with Heidegger’s ideas of ‘present-at-hand’ and ‘ready-at-hand’ will be discussed in more detail in my fourth chapter.

> Dasein is embodied being, it is not simply embedded in the world, but inseparable from it, such that it makes no sense to talk an existence independent of that world.

> conclude Heidegger here?

> so, dasein acts on and through the world to create and convey meaning, but how is the way I perceive that meaning the same to someone else? Talk about Schultz’s stuff.

> include the language related stuff ‘a word means whatever is meant to mean’, it’s a really nice thing to follow on from in the ‘primed sounds’ section

### Schutz’s Phenomenology of the Social World

> Pages 110-110

Alfred Schutz extended phenomenology past the individual and into the social world. His work centred on the problem of intersubjectivity — given that our experiences of the world are our own, how can we achieve a common experience of the world, a shared framework for meaning? If separate individuals do not know how one another experiences the world, how can they come to any understanding of it? How can the relationships between two peoples’ subjective experiences be formed and maintained? Social order arise from the collective action of all of us. Collective action depends on intersubjectivity, our common understandings of the world and our action in it.

Schutz detached himself from the traditional sociological standpoint of individuals such as Max Weber. Modern sociology saw its goal as being to ‘study action in order to uncover the orderliness that lay behind it, an orderliness that could be expressed in terms of general rules’ (Dourish, Page 111, Where the Action Is).

### End summary to consider breaking everything down into

Descartes brought the mind and the body, Husserl brought the lebenswelt, Heidegger brought Dasein, Schutz added intersubjectivity to the lebenswelt, 

## A Call for Calm

> The most potentially interesting, challenging, and profound change implied by the ubiquitous computing era is a focus on calm (Weiser and Brown, Page 7, The Coming Age of Calm Technology).

The goal of calm computing is to counter-act the information overload that comes hand-in-hand with the increased presence of computers in our everyday lives. Calmness mustn’t simply be a property of the information displays themselves, but they should instil a sense of calm in users too. It’s not as straight-forward as reducing the amount of data that is presented to users, nor pacifying the means by which it is brought to their attention. Phones shouldn’t stop ringing, notifications from pushing, and appliances from beeping — though that certainly has something to do with it. In the advent of ubiquitous computing our environment becomes our primary computational interface. The key to calmness is rooted in the design of computers that are able to drift, wilfully, from the centre of our attention to the far reaches of our periphery (Weiser and Brown, Page 8, The Coming Age of Calm Technology).

### Attention, Attention

We are able to devote our attention to sensory stimuli (sensorial attention) and cognitive processes (intellectual attention). At any one moment in time our sensory systems are being bombarded with input, just as memories and thoughts might be occupying our mind. In order to make any sense of the world around us we filter those streams of external stimuli and internal thought, at both a conscious and subconscious level, by a method of selective allocation (Bakker, Elise van den Hoven, and Berry Eggen, Page 72, Haptics conference).

The centre and the periphery in the context of attention are analogous to those of vision. The periphery of attention consists of all potential activities that are not currently at the centre, regardless of whether or not attentional resources are being given them (Bakker, Elise van den Hoven, and Berry Eggen, Page 78, Haptics conf).

The two most important functions of attention proposed by models of attention management are those of selective and divided attention (Bakker, Elise van den Hoven, and Berry Eggen, Page 72, Haptics conference). Selective attention is just as it sounds; the ‘focusing of attention on one stimulus while intentionally ignoring others’ (Bakker, Elise van den Hoven, and Berry Eggen, Page 72, Haptics conference). Divided attention is best exemplified by the notion of multi-tasking — our finite attention resources are spread between several sensorial or intellectual processes.

### Selective Attention

The everyday world provides each of our senses with a persistent and simultaneous torrent of stimuli. Such a mass of sensory input must be analysed before it can be perceived. This analysis, for example, whilst we engage in a conversation amongst a crowd of people, allows us to discern the voice of our conversational partner from the background noise (Bakker, Elise van den Hoven, and Berry Eggen, Page 73, Haptics conference).

Early selection theory suggested that we might only be able to handle one perceptual stream at a time. It proposed that we reject all but one channel of information at a preliminary filtration level. This was in agreement with Cherry’s (1953, Page 978, Experiments in speech recognition) experiments regarding speech recognition, in which a participant was presented with two simultaneously spoken messages. The subjects were tasked with remembering, recalling, and repeating one of these messages and in doing so were unable to recall the content of the second message, despite being aware of its presence. The informational stream is disregarded, or filtered, before its constituent words have been perceived.

Experiments conducted by Moray (Page 56) showed that in certain circumstances, when secondary streams contained words of particular importance to an individual, attention is diverted from the primary informational stream. Deutsch and Deutsch (1963) concluded that this contradicted early selection theory, as ‘a message will reach the same perceptual and discriminatory mechanisms whether attention is paid to it or not’ (Page 83, Attention: Some Theoretical Considerations). Therefore, the 

Early and late theories of selection differed in the ordering of this filtration and perception steps in the process in _. The early theory postulated that the former took place first, and that disregarded streams of information were not perceived, but later theory stated on the contrary that filtration was in fact the last operation in the stack.

### Divided Attention

### The Centre and the Periphery

The ability of multiple informational outputs to simultaneously and passively inform us from our periphery, without the need for our undivided attention, means that we can attune ourselves to many things at once. This, combined with the knowledge that at any time, these peripheral sources can immediately be shifted to the centre of our attention — to be either addressed or acknowledged — is the where the fundamentally calming power of the periphery lies.

### Ambient Media

Therefore, the manner in which information is presented should be considered just as important as the content itself. ‘Context and content work efficiently together as an ensemble, sharing the burden of communication’ (Brown and Duguid, 1996, Keeping it Simple). Just as much as the New York Times wouldn’t print its publications in Comic Sans, the hospital wouldn’t inform you of a loved ones demise via text. A telephone does not adjust the intrusiveness of its ringtone based on the urgency of the call, all phone calls are equal in its eyes, though that’s certainly not the case.

The majority of the electronic devices blink, beep, and vibrate in an attempt to communicate with us, but succeed only in signalling at the very best. So how might the myriad of devices that make up our technological lives bridge the divide and take up residence in our periphery? Norman (2007) suggests that designers should take cues from those phenomena that already do; ‘natural signals inform without annoyance, providing natural, nonintrusive, nonirritating, continuous awareness of the events around us’ (Norman, Pages 58-59, The Design of Future Things). Natural environmental phenomena fall easiest into our periphery as they are those which we have become accustomed to, both individually and evolutionarily. They (the natural world) provide us with a rich tool set to fit system feedback and output to our sophisticated array of senses.

An an example, MIT’s Tangible Media Group developed an ‘ambientROOM’ concept which utilised a number of ambient media such as ‘such as light, sound, airflow, and water movement’ (Ishii, Page 1, Tangible Bits) which were directly inspired by ‘natural phenomena such as wind, sunlight, or the sounds of a rainforest’ (Ishii, Page 1, ambientROOM). Ishii (1998) interprets the centre and periphery of attention as ‘foreground’ and ‘background’ of awareness — multiple sources of information can be monitored concurrently in the background whilst we are concentrating on the primary source in the foreground (Ishii, Page 1, ambientROOM).

One feature of the ambientROOM was the use of rain, which attempted to subtly convey the number of hits a website was receiving by manifesting each view as the sound of a raindrop. The website activity could be monitored peripherally as the soundscape phased from trickles to torrents and back throughout the day. Corresponding to specific events, be that a feature on a blog or perhaps even a technical fault with the web server. It was a move to a more natural display of information, but despite this sound, natural or otherwise, can be a difficult sensory stimulus to ignore. It requires a great deal of finesse on the part of the designer to ensure that it avoids entering the realms of distraction and annoyance. ‘The individual, not the environment, must be in charge of moving things from center to periphery and back’ (Weiser and Brown, Page 13, The Coming Age of Calm Technology) for it must ‘offer, but not demand’ (Weiser and Brown, Page 14, The Coming Age of Calm Technology). The MIT Tangible Media Group observed their use of raindrops crossing this divide whilst testing their ambientROOM and opted instead to employ the use of light, a medium perhaps more suited to ambient conveyance. The group ‘built a thin water tank outfitted with a solenoid-driven float … With each pull, the float creates a ripple on the surface of water. Light projected onto the water tank from above casts a subtle but poetic image of ripples on
the ceiling of the room’ (Ishii, Page 6, Tangible Bits). It was much more successful than its audible predecessor, testimony to the trickiness of (peripheral) sonic displays of information.

### Embedded and Embodied

Perhaps the earliest and most elegant example of calm technology is Natalie Jemerijenko’s ‘Live Wire’ (Weiser and Brown, Page 15, The Coming Age of Calm Technology). Created whilst an artist-in-residence at Xerox’s PARC in 1995; the installation consists of a piece of plastic string connected to an electric motor. An electric motor which flutters with each bit of information that passes along an ethernet cable. It resides in the corner of an unused corridor, visible and audible through the open doors of nearby offices, not enough to be a distraction, but sufficient as to provide an insight into the busyness of the network. The more data being transferred on the network the faster the string spins and whirrs.

> the authors of the paper mention iterative sound with regard to design; sounds have to be primed, which means sounds have to be known to mean something, the sounds themselves, prior to priming don’t mean anything to me, and thus don’t rank highly on my attenuation filter. Is it a matter of learning what they sounds mean, or iterating in order to find sounds that already have a meaning (associated with whatever function/emotion the ambience wishes to elicit)?

## Embodied Virtuality

The earliest artefacts of ubiquitous computing, developed by Weiser and his colleagues at the Computer Science Lab in Xerox’s PARC, came in the form of tabs, pads, and boards. Each was designed to suit a relative scale at which humans interacted with the world; the inch, foot, and the yard. As a suite of devices they were analogous to the post-it notes, sheets of paper and whiteboards that already inhabited the working environment. Each offered many of the same affordances as its ‘analog’ predecessor; augmented with the digital functionality facilitated by constant network connection, amongst the usual advantages. They succeeded in demonstrating the distributed nature of ubiquitous computing, but absent was Weiser’s notion of ‘embodied virtuality’ (Weiser, Page 98, The Computer of the 21st Century). Tabs, pads, and boards merely provided windows from the physical world into that of the virtual. Windows that were populated by the familiar icons, menus, and pointing devices of the graphical user interface (GUI) model — something it had in common with the personal computing paradigm it sought to supersede. The context in which computing took place was now changing, but the interaction with the computers remaining much the same. It was certainly a step in the right direction, but there was work to be done.

### Marbles and Voicemail

The systems involved in voicemail are still to this day a source of anger and annoyance for many. It’s often quicker and easier to immediately return someone’s phone call than it is to navigate the archaic systems in which their message has been stored. Visual voicemail removed much of the pain of interfacing with these systems by providing an alternate mode of interaction. Rather than primitive vocalised menus and touch-tone inputs we were granted the luxury of a GUI. But despite its superior user experience it’s yet to be adopted by all mobile phone operators.

> Visual voicemail provides a graphical visualisation of the system, the messages within it and the operations that can functions that are available to the user.

Long before the concept of visual voicemail, or even mobile phones, Durrell Bishop contemplated a different type of interaction for the common telephone answering machine. Whilst studying his MA in Interaction Design at the Royal College of Art in London he prototyped the ‘Marble Answering Machine’ (Smith, Page 60, The Hand that Rocks the Cradle). Each message that was recorded on the machine was mapped to a physical marble which was released by a mechanism so that it rolled into and settled in a linear trough. The presence of indentations on the answering machine and peripherals that surround it afford placing the marble within. The location of these indentations corresponds to their function, for example, placing a marble atop the phone would dial the phone number of the individual who left the message. Messages are deleted when the marble is returned to the machine.

The function of the marble extends beyond its use within the technical system. The marble itself contains no data, it is simply a token representation of the message stored within the digital system. The marble is, as well as being the physical instantiation of a digital voice regarding, still just a marble, and so it has the same potential for activity as any other. As Bishop’s (Bishop, Marble Answering Machine) demonstration shows, it can kept in a dish for the desired recipient, have a note attached to it, and be hidden away in a drawer for safe keeping.

The marble answering machine is a fine example of the embodied virtuality that Weiser (1991) presented, but as Dourish (2001) notes; the externalisation of the system grants it an ‘at-a-glance readability’ which ‘stands in marked contrast to the “invisibility” of ubiquitous computing’ (Page 42, Where the Action Is). This apparent paradox and Weiser’s use and definition of the word ‘invisible’ is something that I will return to in the next chapter.

> though, in these examples, the computer *is* invisible. For the user, they are simply doing what they want to do, which is listen to messages left on their machine.

> this was the embodied virtuality that Weiser had alluded to, and it spurred the next movement in physical representations of and interactions with computers

### Tangible Bits

> origin of tangible bits in the work of Negroponte?

> look at the bricks and the initial graspables

> tangible media group called this ‘tangible bits’.

> Dourish’s issues with tangible computing — one of the primary issues with vocalised interfaces is sequentiality

## Affording a Future

The term ‘affordance’ emerged from the ecological psychology of J. J. Gibson. Gibson (1986) defined the affordances of an environment as ‘…what it offers the animal, what it provides or furnishes, either for good or ill’ (Gibson, Page 127, The Ecological Approach to Visual Perception). An object affords certain actions to a entity based on its physicality and on the capabilities of the entity. Norman (1988) introduced the concept of affordances to the design of everyday things as a means by which users might deduce — without complex cognitive process — the function of an object from its form:

> …the term affordance refers to the perceived and actual properties of the thing, primarily those fundamental properties that determine just how the thing could possibly be used. A chair affords support and, therefore, affords sitting … Knobs are for turning. Slots are for inserting things into. Balls are for throwing or bouncing. When affordances are taken advantage of, the user knows what to do just by looking: no picture, label, or instruction is required. (Norman, Page 9, The Psychology of Everyday Things)

Much ambiguity arose around the definition of affordance when Norman (1988) first introduced the concept to the field of HCI. Norman (Page 68, The Design of Future Things) sees the visibility of an affordance as being a critical factor — if an affordance goes unnoticed or, in the words of Gaver, (Page 80, Technology Affordances) is hidden, then it is worthless (in its current form and context, at least). However, McGrenere and Ho (Page 1, Affordances: Clarifying and Evolving a Concept) suggest that Gibson intended an affordance to mean a opportunity for action that existed within an environment, regardless of an individual’s ability to perceive it. This led to Norman (1999) outlining the difference between ‘perceived affordances’ — core to his notions of usability — and ‘real affordances’. ‘Perceived affordances are often more about convention than reality’ (Page 124, The Invisible Computer) and their perception is dependant on an individual’s culture, social settings, and existing knowledge.

Gaver (1991), in suggesting affordances as a tool for user-centric analysis of technologies, proposes that affordances ‘are not passively perceived, but explored’ (Page 82, Technology Affordances). Though this is of more relevance to complex systems than it is to everyday things, Norman’s (1988) principles of visibility, feedback, and forcing functions go a long way to providing designers with the tools to develop tangible computing systems that reward, rather than punish, their users for exploring them and their capabilities. 

- visibility



- feedback



- forcing functions



Dourish (2004) outlined a number of issues that arise in tangible computing systems

> Gaver had it covered with this:-

Gaver’s (1991) logical progression of sequencing and nesting affordances gives designers of tangible computing systems 

## Conclusion

## Bibliography