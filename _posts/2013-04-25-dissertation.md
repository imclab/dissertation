## Abstract

[TBC]

**Keywords:** Ubiquitous Computing, Physical Computing, Tangible Computing, Pervasive Computing, Internet of Things, Embodied Interaction, Post-WIMP, Tangible Interfaces, Reality-Based Interfaces, Human Computer Interaction, Ecological Psychology, Affordances, Product Design, Interaction Design, Emotional Design, User-Centred Design.

## Introduction

- The conundrum of computer literacy
- We take our work to the computer
- Computing is already and will become far more than the fanciful rectangles of today’s popular technology
- The fallacy of the manual readers
- The computer has so much potential to enrich our everyday lives
- When computers are fun, playful, and forgiving of ‘our errors’ we are much more likely to explore and that gives way to a learn once (or stumble upon once) and remember forever model of computer interaction.
- I cannot understand how something works, I cannot create a ‘model’ of the system, unless I engage with it, or watch someone else doing so.

- We learn to use computers, rather than learning to do something with the help of computers.
- We don’t have to learn the basic principles of physics before we do something ‘analogue’ (think of an example here?), so why do we have to do so in regard to computers? Why can’t computers recognise our familiarity with the real world and capitalise on that?

‘Instead of always taking work to the computer, why not put computation wherever it might be needed?’ (Dourish, Page 28, Where the Action Is).

> Add in dourish’s little trip down the interaction memory lane here?

The artefacts of Today’s modern computing technology are almost unrecognisable as descendants of their primitive predecessors. The computer entered the commercial market as a static behemoth that resided almost exclusively in the cupboards, back rooms and basements of corporate and governmental offices. It had no single operator; its time and resources were shared between multiple users. This was the era of the mainframe computer.

The first major paradigm shift occurred in the 1980’s, as the mainframe escaped its dimly-lit confines and fixed itself firmly and securely to the desktops of individual employees and hobbyists. The computer-to-human relationship was a one-to-one affair, and so began the age of the personal computer. As the personal computer rose to prominence as its numbers and use grew, it did so surrounded by somewhat of an ‘arcane aura’ (Weiser, Page 94, The Computer for the 21st Century). It spoke a different language, indecipherable to everyday folk. It operated outside of the confines of everyday life, accessible only whilst seated before it at a desk. Its form and the mode by which we interacted with it were changing very little. It was yet to undergo anything akin to a metamorphosis; still a far cry from the techno-utopian futures that had been promised by science fiction. In an ‘age of beige boxes’ (Dourish, Page 27, Where the Action Is), something more than a newly designed cuboid was necessary to change the nature of computing as we knew it. Something had to happen at a fundamental level, a re-imagining of our future and the role that computers played in it.

Mark Weiser witnessed the rise of the personal computer whilst head of the Computer Science Lab (CSL) at Xerox’s Palo Alto Research Centre (PARC) in California. The interdisciplinarity of PARC exposed Weiser to the ideas, thoughts and insights of sociologists, psychologists, and anthropologists, which ultimately inspired him and his colleagues ‘to take a radical look at what computing and networking ought to be like’ (Weiser, Ubiquitous Computing #1). Weiser envisioned a type of computing that was ubiquitous. It was the inverse of its mainframe predecessor; providing each user with many devices, in the tens if not hundreds. Ubiquitous computing (ubicomp) would see computers present at each and every level of our day-to-day lives, ‘imbedded in walls, chairs, clothing, light switches, cars - in everything’ (Weiser and Brown, Page 4, The Coming Age of Calm Technology). Ubicomp is defined not just by the abundance of computers, but also by their persistent and total connectedness, and the underlying infrastructures that facilitate such a thing.

> I should probably mention some foundational technologies here (RFID etc.) perhaps with regard to context awareness?

PARC stayed true to its philosophy of “Build what you use, and use what you build” (Want, Page 6, An Introduction to Ubiquitous Computing [Ubiquitous Computing Fundamentals]) and, under the guidance of Weiser, embarked on a project to realise ubicomp. Given the high cost and limited capabilities of existing technologies, it was — slightly ironically — ubiquitousness on a small-scale. However, it provided the CSL team with the necessary environment in which to explore the requirements, effects, and emergent traits of ubicomp.

Weiser’s vision and the work being undertaken at PARC was not going unnoticed in the wider world. Throughout the 90s ubicomp influenced a number of projects that explored the possibilities of this kind of computing. Projects that took place in both corporate and academic research labs, run by the likes of IBM and Hewlett Packard, MIT and Georgia Tech. With each new project came a new term that more succinctly conveyed the nature of its unique brand of ubiquitous computing, whether for business reasons or otherwise. Such terms include pervasive, tangible, and physical, some of which I will return to in the coming chapters.

The fundamental characteristics of ubiquitous computing that Weiser himself — explicitly and implicitly — outlined in ‘The Computer for the 21st Century’ and publishings thereafter will form the basis of this dissertation. Characteristics which addressed aspects of the current paradigm of personal computing and set the precedent for technologies that would more appropriately fit themselves to the real-world and capitalise on our familiarity with it. The refinement of these characteristics in the new fields that emerged in the wake of ubicomp will build on this base, conducted through the exploration and analysis of the archetypal projects from each area.

A most critical aspect of Weiser’s vision for a ubiquitous computing, one which can clearly be seen in the projects that it has both influenced and given rise to, is the concept of embodiment. It’s first mentioned in the context of ‘embodied virtuality’ (Weiser, Page 98, The Computer for the 21st Century) as the notion of ‘drawing computers from their electronic shells. The “virtuality” of computer-readable data -- all the different ways in which it can be altered, processed and analyzed -- is brought into the physical world’ (Weiser, Page 98, The Computer for the 21st Century). It’s the philosophical, psychological, and sociological underpinning of the ubiquitous computing paradigm, and will be the topic of the first chapter of this dissertation. It will call upon the work of Paul Dourish regarding embodied interaction. Focussing on his analysis of the phenomenological traditions founded by Edmund Husserl and further developed by Martin Heidegger.

> hat tip to ‘tangible bits’ in regard to embodiment?

The thought of computational devices being inherently ‘calm’ is perhaps at odds with the situation we find ourselves in Today — surrounded by a plethora of gizmos and gadgets, each vying for our attention with its incessant bleeping, chirping, and rumbling. Weiser and Brown (1996, Page 7) warned that “if computers are everywhere they better stay out of the way” (Weiser and Brown, Page 7, The Coming Age of Calm Technology). Efforts to make computing more ambient and natural will be the focus of my second chapter.

One of the more commonly misunderstood aspects of ubicomp is its desire to become invisible. How, in a world so full of technology, we can be unaware of its presence is the topic of my third chapter. It will build on the philosophical and psychological foundations introduced in the first chapter to ascertain quite how a technology as pervasive as ubicomp might succeed in disappearing from our consciousness. Technology is a tool, a means to an end, the less we can focus on the tool itself and instead on what it is that we are trying to achieve, the better.

In the final chapter, I will review the current state and direction of ubiquitous computing, contextualising it within the larger technological landscape. Giving reference to the likes of Adam Greenfield and Bruce Sterling with the aim of identifying new characteristics that have emerged from its maturation in the last two decades.

## Embodiment

The notion of embodiment is the foundational underpinning of ubiquitous computing, it rudimentarily concerns itself with the fact that ‘humans are of and in the everyday world’ (Weiser, 1993, Some Computer Science Issues of Ubiquitous Computing). Dourish (2001) reviews the philosophy of embodiment in the context of tangible and social computing in his book ‘Where the Action Is’ and this publication will be the focus of this chapter.

> extend this introduction to include more relevant terms?

At around the same time that ubiquitous computing was finding its feet, ideas and technologies surrounding the starkly contrasted approach of virtual reality were also building up steam. Virtual reality proposes a model that seeks to inhabit the user in a computer-generated world. It detaches our consciousness from its fleshy confines and beams it into the fictional environment which it has created for us. A three-dimensional space designed to resemble the real world — often complete with naive physics, occlusion, and even proprioception — as to exploit our familiarity with the nature and structure of it. This use of the real world as a metaphor for interaction is distinctly different to using at as medium for interaction (Dourish, Page 101, Where the Action Is). Even in the most immersive virtual reality environments, ‘users are disconnected observers of a world they do not inhabit directly’ (Dourish, Page 102, Where the Action Is). Just as ‘…a disembodied brain could not experience the world in the same way we do’ (Dourish, Page 18, Where the Action Is), nor can our disconnected consciousness inhabit a virtual reality, ‘because our experience of the world is intimately tied to the ways in which we act in it’ (Dourish, Page 18, Where the Action Is).

> There is no homunculus sitting inside our heads, staring out at the world through our eyes, enacting some pan of action by manipulating our hands, and checking carefully to make sure that we don’t overshoot when reaching for the coffee cup. We inhabit our bodies and they in turn inhabit the world, with seamless connections back and forth’ (Dourish, Page 102, Where the Action Is).

Cartesian dualism, closely associated with the philosophy of René Descartes, separates the mind and body as two distinctly different entities — to ‘think’ and to ‘be’ are two disparate sets of phenomena (Dourish, Page 107, Where the Action Is). It’s clear that virtual reality adheres to this notion, but as we will now see, ubiquitous computing complies more with the phenomenological tradition that followed on from these ideas of duality.

Weiser (1991) alludes to the contrasting stance of ubiquitous computing with his use of the phrase ‘embodied virtuality’ (Weiser, Page 98, The Computer for the 21st Century). Rather than the user entering the computer’s domain, the computer is lured from its electronic shell into the real world — ‘The site of interaction is the world of the user, not that of the system. The world … may be imbued with computation, but the computer itself takes a back seat’ (Dourish, Page 38, Where the Action Is).

Phenomenology was founded by Edmund Husserl (1859-1938) as an exploration of human experience and perception (Dourish, Page 104, Where the Action Is). Husserl was attempting to address the abstract and idealised approach of scientists and mathematicians of the era. Such methodologies distanced themselves and their work from everyday practical concerns, and in doing so, the live experience of people acting in the world. Husserl ‘envisioned a science that was firmly grounded on the phenomena of experience, which in turn meant developing the philosophy of experience as a rigorous science’ (Dourish, Page 105, Where the Action Is).

Husserl proposed phenomenology as a method for examining the nature of intentionality; the way mental states could refer to elements of external reality. It aims to uncover the relationship between the objects of consciousness and our mental experiences of them — how ‘noema’ relate to ‘noesis’. Phenomenologists must not assume an objects existence based on its perception — for this is its objective, to understand how in perceiving something we assume its existence.

Husserl states that there is a parallelism between the objects of perception and the acts of perception. For example, when I see a rabbit, I have not only to recognise that what I’m seeing is a rabbit, but also that what I’m doing is seeing it (as opposed to imagining it or remembering it). Husserl saw that mental acts could become phenomena of experience as one referred and reflected on them (Dourish, Page 105, Where the Action Is). When an individual recognises that what they are seeing is a rabbit they move from the world of everyday affairs, beyond the sensory stimuli, and into the life-world. ‘The life-world [or lebenswelt] is the intersubjective, mundane world of background understandings and experiences of the world’ (Dourish, Pages 105-106, Where the Action Is).

Martin Heidegger (1889-1976) was a student of Husserl and used his work on phenomenology as a starting point as he too sought to uncover to intentionality of experience. Heidegger, however, saw his predecessor’s focus on mental phenomena occurring in isolation from the body as fundamentally flawed. He reversed Descartes’ dictum ‘cogito ergo sum’ to propose that ‘clearly one needed to be in order to think’ (Dourish, Page 107, Where the Action Is). To Heidegger, our being in the world and our experience of it shapes the way we understand it ‘because our understanding of the world is essentially an understanding of how we are in it’ (Dourish, Page 107, Where the Action Is). Descartes saw that the mind was the seat of reason and meaning — we observe the world and give it meaning by relating it to abstract understandings of (an idealised) reality. Heidegger situated the meaningfulness of everyday experience, not in the head, but in the world. ‘Heidegger asked, “How does the world reveal itself to us through our encounters with it?”’ (Dourish, Page 107, Where the Action Is).

‘Meaning inheres in the world as we find it’ (Dourish, Page 108, Where the Action Is) — the things we do, practically, and the ways in which we act and how this action is accommodated in the world is what makes the world meaningful to us. At the heart of this thinking is Heidegger’s concept of Dasein, the essence of being human and how ‘being’ is inseparable from the world in which it occurs (Dourish, Page 108, Where the Action Is). Dasein’s orientation toward the world is a fundamentally practical one, but action is not just carried out on the world, but also through it. Dasein’s use of tools and equipment, the distinction between the two, together with Heidegger’s ideas of ‘present-at-hand’ and ‘ready-at-hand’ will be discussed in more detail in my fourth chapter.

> Dasein is embodied being, it is not simply embedded in the world, but inseparable from it, such that it makes no sense to talk an existence independent of that world.

> conclude Heidegger here?

> so, dasein acts on and through the world to create and convey meaning, but how is the way I perceive that meaning the same to someone else? Talk about Schultz’s stuff.

> include the language related stuff ‘a word means whatever is meant to mean’, it’s a really nice thing to follow on from in the ‘primed sounds’ section

## A Call for Calm

> The most potentially interesting, challenging, and profound change implied by the ubiquitous computing era is a focus on calm (Weiser and Brown, Page 7, The Coming Age of Calm Technology).

The goal of calm computing is to counter-act the information overload that comes hand-in-hand with the increased presence of computers in our everyday lives. Calmness mustn’t simply be a property of the information displays themselves, but they should instil a sense of calm in users too. It’s not as straight-forward as reducing the amount of data that is presented to users, nor pacifying the means by which it is brought to their attention. Phones shouldn’t stop ringing, notifications from pushing, and appliances from beeping — though that certainly has something to do with it. In the advent of ubiquitous computing our environment becomes our primary computational interface. The key to calmness is rooted in the design of computers that are able to drift, wilfully, from the centre of our attention to the far reaches of our periphery (Weiser and Brown, Page 8, The Coming Age of Calm Technology).

### Attention, Attention

It’s common within the worlds of psychology and neuroscience to consider attention as a finite resource which is shared between sensory stimuli (sensorial attention) and cognitive processes (intellectual attention). The finiteness of our attention means that we cannot be fully aware of all that is taking place at any one time. At both conscious and subconscious levels we filter those streams of external stimuli and internal thought by a method of selective allocation in order to make sense of the world around us (Bakker, Elise van den Hoven, and Berry Eggen, Page 72, Haptics conference).

The two most important functions of attention proposed by models of attention management are those of selective and divided attention (Bakker, Elise van den Hoven, and Berry Eggen, Page 72, Haptics conference). Selective attention is just as it sounds; the ‘focusing of attention on one stimulus while intentionally ignoring others’ (Bakker, Elise van den Hoven, and Berry Eggen, Page 72, Haptics conference). Divided attention is best exemplified by the notion of multi-tasking — our finite attention resources are spread between several sensorial or intellectual processes.

### Selective Attention

Selective attention theories usually only concern sensorial attention and describe our attention as a mental filter (Bakker, Elise van den Hoven, and Berry Eggen, Page 73, Haptics conference). The everyday world provides each of our senses with a persistent and simultaneous torrent of stimuli. Such a mass of sensory input must be analysed before it can be perceived. This analysis, for example, whilst we engage in a conversation amongst a crowd of people, allows us to discern the voice of our conversational partner from the background noise.

Early selection theory suggested that we might only be able to handle one perceptual stream at a time. It proposed that we reject all but one channel of information at a preliminary filtration level. This was in agreement with Cherry’s (1953, Page 978, Experiments in speech recognition) experiments regarding speech recognition, in which a participant was presented with two simultaneously spoken messages. The subjects were tasked with remembering, recalling, and repeating one of these messages and in doing so were unable to recall the content of the second message, despite being aware of its presence. The informational stream is disregarded, or filtered, before its constituent words have been perceived.

Deutsch and Deutsch (1963) disagreed with this model and instead proposed a late selection theory, putting forward the example of 

Early and late theories of selection differed in the ordering of this filtration and perception steps in the process in _. The early theory postulated that the former took place first, and that disregarded streams of information were not perceived, but later theory stated on the contrary that filtration was in fact the last operation in the stack.

### Attenuation Theory

> selective attention is simply a filter

Whilst our attention is directed at one primary stream of information, be that from a conversation or a computer, we selectively disregard secondary streams, but not entirely. Attenuation theory, which followed on from late selection theory, proposes that a weakened channel from these peripheral sources permeates our selective filters and is perceived — if to a lesser extent.

> top-down priming enables for more acute perception of these secondary, weak streams of information

### Divided Attention

### The Centre and the Periphery

### Natural Phenomena

### Ambient Media

### Embedded and Embodied

Perhaps the earliest and most elegant example of calm technology is Natalie Jemerijenko’s ‘Live Wire’ (Weiser and Brown, Page 15, The Coming Age of Calm Technology). Created whilst an artist-in-residence at Xerox’s PARC in 1995; the installation consists simply of a piece of plastic string connected to an electric motor. An electric motor which flutters with each bit of information that passes along an ethernet cable. It resides in the corner of an unused corridor, visible and audible through the open doors of nearby offices, not enough to be a distraction, but sufficient as to provide an insight into the busyness of the network. The more data being transferred on the network the faster the string spins and whirrs.

> the authors of the paper mention iterative sound with regard to design; sounds have to be primed, which means sounds have to be known to mean something, the sounds themselves, prior to priming don’t mean anything to me, and thus don’t rank highly on my attenuation filter. Is it a matter of learning what they sounds mean, or iterating in order to find sounds that already have a meaning (associated with whatever function/emotion the ambience wishes to elicit)?

### My Point

What does natural even mean?

Any one sound cannot mean one thing to all people. The sound of birdsong in the morning is considered to be a calming, reassuring sound as it means that everything is alright — but really though? As long as birds are singing the world it alright? Does the absence of bird song mean that everything is not alright?

Am I trying to say that the ‘learn once remember forever’ philosophy is wrong? Am I backing the learning whilst doing approach?

Can affordances really be universal? Are they impacted by cultural factors?

It’s about producing objects that can do things, not objects that you can do things with?

## The Disappearance of the Computer

The idea of a form of computing that is both everywhere, in everything, and yet inconspicuous enough that it might be thought of as being invisible is somewhat paradoxical. Weiser (1991) offers the example of the solenoid to explain the means by which such technologies fade into the background and from our _:-

Cheap, small, efficient electric motors made it possible first to give each machine or tool its own source of motive force, then to put many motors into a single machine.

A glance through the shop manual of a typical automobile, for example, reveals twenty-two motors and twenty-five more solenoids. They start the engine, clean the windshield, lock and unlock the doors, and so on. By paying careful attention it might be possible to know whenever one activated a motor, but there would be no point to it.

This definition or understanding of invisibility still feels too literal and is rendered insufficient with the advent 

> the influence of the new embodied virtuality design trends on ubiquitous computing and in turn the MIT tangible media group

The influence of the art and design worlds, from individuals such as Natalie Jeremijenko and Durrell Bishop, realised Weiser’s concept of embodied virtuality. Durrell Bishop’s ‘Marble Answering Machine’ re-imagined the way in which people interacted with voicemail messages. Each voice recording is represented by a marble, when a message is left on the machine a marble rolls down an incline into a trough. The virtual  This marble is a physical manifestation of a virtual object, it’s the immaterial 

### Tangible Bits

### 

> invisibility through ‘ready-at-hand’, which is facilitated by theories of ecological perception and the notion of affordances (which should no longer be thought of as a property, but as a medium through which the designer can communicate with the user). Through the retraction if a tool from being present-at-hand to ready-at-hand, it disappears from our immediate concerns, not entirely from view (this is the notion of invisibility you should strive for, not literal disappearance)

## Conclusion

## Bibliography